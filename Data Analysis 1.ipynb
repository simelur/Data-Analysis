{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9e8e0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\1\\ipykernel_21104\\3175347921.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# numpy compat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mis_numpy_dev\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_is_numpy_dev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m from pandas.compat.numpy import (\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mnp_version_under1p19\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\compat\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# numpy versioning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m from pandas.util._decorators import (  # noqa:F401\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mAppender\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mSubstitution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcache_readonly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproperties\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcache_readonly\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m from pandas._libs.tslibs import (\n\u001b[0;32m     15\u001b[0m     \u001b[0mNaT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\interval.pyx\u001b[0m in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor())\n",
    "])\n",
    "#1. Data Collection and Pre-processing\n",
    "# Load data (replace with your actual file names)\n",
    "df = pd.read_csv('PENICAL ALL.csv')\n",
    "\n",
    "# Split dataframe into features (X) and target (y)\n",
    "X = df.drop(columns=['SPAD'])  # Drop 'sample_id' and 'SPAD' to get the features\n",
    "y = df['SPAD']  # Target variable\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed193c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Explore data statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a7723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Pre-processing-Normalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "standardized_df = scaler.fit_transform(df)\n",
    "X_train_scaled = scaler.fit_transform(df)\n",
    "X_test_scaled = scaler.transform(df)\n",
    "\n",
    "# Normalize spectral data\n",
    "df_normalized = (df- df.mean()) / df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed647266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply Savitzky-Golay filter # smoothing\n",
    "from scipy.signal import savgol_filter\n",
    "smoothed_df = savgol_filter(df_normalized, window_length=11, polyorder=3, axis=0)\n",
    "\n",
    "# Calculate correlation coefficients #3. Data Analysis\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Extract correlations with SPAD\n",
    "correlations_with_spad = correlation_matrix['SPAD'].drop('SPAD')\n",
    "\n",
    "# Display correlation values\n",
    "print(correlations_with_spad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218fe7da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Measures the statistical relationship between two features.\n",
    "# Sort correlations with SPAD #Strongest linear relationships with the target variable. \n",
    "sorted_correlations = correlations_with_spad.abs().sort_values(ascending=False)\n",
    "print(\"Top features correlated with SPAD:\")\n",
    "print(sorted_correlations.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98357dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cc5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. cross-validation\n",
    "#Robust Performance Estimate: It provides a more reliable estimate of the model's performance \n",
    "#by training and testing the model on different subsets of the data.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Example data (replace with your dataset)\n",
    "X = np.random.rand(100, 10)  # 100 samples, 10 features\n",
    "y = np.random.rand(100)      # 100 samples, 1 target variable\n",
    "# Initialize the Random Forest Regressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=175)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "# Note: cross_val_score returns negative MSE values by default\n",
    "mse_scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Convert negative MSE to positive MSE\n",
    "mse_scores = -mse_scores\n",
    "\n",
    "# Calculate the average MSE\n",
    "average_mse = np.mean(mse_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"MSE scores for each fold:\", mse_scores)\n",
    "print(\"Average MSE:\", average_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef2e91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "# Standardize the features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Apply PCA\n",
    "n_components = 10  # Number of principal components to keep\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Verify the shape of the transformed data\n",
    "print(\"Shape of X_pca:\", X_pca.shape)\n",
    "# Fit PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# Plot explained variance ratio\n",
    "plt.figure(figsize=(6, 2))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by Number of Components')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print the explained variance ratio for each component\n",
    "print(\"Explained variance ratio by each component:\")\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08efff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200,],\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "    'min_samples_split': [30,35,40,45,50],\n",
    "    'min_samples_leaf': [7,8,9,10, 11],\n",
    "    'max_features': [1, 2, 3, 4, 5]  # Number of features to consider at each split\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf = RandomForestRegressor(random_state=175)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Get the best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "best_mse_scores = cross_val_score(best_rf, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "best_mse_scores = -best_mse_scores\n",
    "average_best_mse = np.mean(best_mse_scores)\n",
    "print(\"Best Random Forest Cross-validated MSE:\", average_best_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c78cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Define the model\n",
    "rf = RandomForestRegressor(random_state=175)\n",
    "\n",
    "# Initialize RFE with the Random Forest model and select the top 5 features\n",
    "rfe = RFE(estimator=rf, n_features_to_select=5, step=25)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_train.columns[rfe.support_]\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "\n",
    "# Transform the data to include only the selected features\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rpd = np.std(y_true) / rmse\n",
    "    return r2, rmse, mae, mse, rpd\n",
    "\n",
    "def display_metrics(model_name, y_train, y_train_pred, y_test, y_test_pred):\n",
    "    print(f\"---{model_name}---\")\n",
    "    print(\"Train Metrics:\")\n",
    "    train_metrics = calculate_metrics(y_train, y_train_pred)\n",
    "    print(f\"R2: {train_metrics[0]}, RMSE: {train_metrics[1]}, MAE: {train_metrics[2]}, MSE: {train_metrics[3]}, RPD: {train_metrics[4]}\")\n",
    "    \n",
    "    print(\"Test Metrics:\")\n",
    "    test_metrics = calculate_metrics(y_test, y_test_pred)\n",
    "    print(f\"R2: {test_metrics[0]}, RMSE: {test_metrics[1]}, MAE: {test_metrics[2]}, MSE: {test_metrics[3]}, RPD: {test_metrics[4]}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Re-train the Random Forest model using only the selected features\n",
    "rf.fit(X_train_rfe, y_train)\n",
    "y_train_pred_rf = rf.predict(X_train_rfe)\n",
    "y_test_pred_rf = rf.predict(X_test_rfe)\n",
    "display_metrics(\"Random Forest with RFE\", y_train, y_train_pred_rf, y_test, y_test_pred_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791115af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# RFE and BPNN\n",
    "# Define the model for RFE\n",
    "rf = RandomForestRegressor(random_state=175)\n",
    "\n",
    "# Initialize RFE with the Random Forest model and select the top 5 features\n",
    "rfe = RFE(estimator=rf, n_features_to_select=5, step=25)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_train.columns[rfe.support_]\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "\n",
    "# Transform the data to include only the selected features\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_rfe = scaler.fit_transform(X_train_rfe)\n",
    "X_test_rfe = scaler.transform(X_test_rfe)\n",
    "\n",
    "# Define the BPNN model\n",
    "def create_bpnn(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Create and train the BPNN model\n",
    "bpnn = create_bpnn(X_train_rfe.shape[1])\n",
    "history = bpnn.fit(X_train_rfe, y_train, epochs=400, batch_size=10, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_bpnn = bpnn.predict(X_train_rfe).flatten()\n",
    "y_test_pred_bpnn = bpnn.predict(X_test_rfe).flatten()\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rpd = np.std(y_true) / rmse\n",
    "    return r2, rmse, mae, mse, rpd\n",
    "\n",
    "def display_metrics(model_name, y_train, y_train_pred, y_test, y_test_pred):\n",
    "    print(f\"---{model_name}---\")\n",
    "    print(\"Train Metrics:\")\n",
    "    train_metrics = calculate_metrics(y_train, y_train_pred)\n",
    "    print(f\"R2: {train_metrics[0]}, RMSE: {train_metrics[1]}, MAE: {train_metrics[2]}, MSE: {train_metrics[3]}, RPD: {train_metrics[4]}\")\n",
    "    \n",
    "    print(\"Test Metrics:\")\n",
    "    test_metrics = calculate_metrics(y_test, y_test_pred)\n",
    "    print(f\"R2: {test_metrics[0]}, RMSE: {test_metrics[1]}, MAE: {test_metrics[2]}, MSE: {test_metrics[3]}, RPD: {test_metrics[4]}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Display metrics\n",
    "display_metrics(\"BPNN with RFE\", y_train, y_train_pred_bpnn, y_test, y_test_pred_bpnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ec213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Generate a random regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=175)\n",
    "\n",
    "# Define the model for RFE\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=100)\n",
    "\n",
    "# Initialize RFE with the XGBoost model and select the top 5 features\n",
    "rfe = RFE(estimator=xgb_model, n_features_to_select=5, step=25)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_train.columns[rfe.support_]\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "\n",
    "# Transform the data to include only the selected features\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_rfe = scaler.fit_transform(X_train_rfe)\n",
    "X_test_rfe = scaler.transform(X_test_rfe)\n",
    "\n",
    "# Train the XGBoost model with the selected features\n",
    "xgb_model.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_xgb = xgb_model.predict(X_train_rfe)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test_rfe)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rpd = np.std(y_true) / rmse\n",
    "    return r2, rmse, mae, mse, rpd\n",
    "\n",
    "def display_metrics(model_name, y_train, y_train_pred, y_test, y_test_pred):\n",
    "    print(f\"---{model_name}---\")\n",
    "    print(\"Train Metrics:\")\n",
    "    train_metrics = calculate_metrics(y_train, y_train_pred)\n",
    "    print(f\"R2: {train_metrics[0]}, RMSE: {train_metrics[1]}, MAE: {train_metrics[2]}, MSE: {train_metrics[3]}, RPD: {train_metrics[4]}\")\n",
    "    \n",
    "    print(\"Test Metrics:\")\n",
    "    test_metrics = calculate_metrics(y_test, y_test_pred)\n",
    "    print(f\"R2: {test_metrics[0]}, RMSE: {test_metrics[1]}, MAE: {test_metrics[2]}, MSE: {test_metrics[3]}, RPD: {test_metrics[4]}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Display metrics\n",
    "display_metrics(\"XGBoost with RFE\", y_train, y_train_pred_xgb, y_test, y_test_pred_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cc2f66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Generate a random regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=175)\n",
    "\n",
    "# Define the model for RFE\n",
    "elnet_model = ElasticNet(random_state=100)\n",
    "\n",
    "# Initialize RFE with the Elastic Net model and select the top 5 features\n",
    "rfe = RFE(estimator=elnet_model, n_features_to_select=5, step=25)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_train.columns[rfe.support_]\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "\n",
    "# Transform the data to include only the selected features\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_rfe = scaler.fit_transform(X_train_rfe)\n",
    "X_test_rfe = scaler.transform(X_test_rfe)\n",
    "\n",
    "# Train the Elastic Net model with the selected features\n",
    "elnet_model.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_elnet = elnet_model.predict(X_train_rfe)\n",
    "y_test_pred_elnet = elnet_model.predict(X_test_rfe)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rpd = np.std(y_true) / rmse\n",
    "    return r2, rmse, mae, mse, rpd\n",
    "\n",
    "def display_metrics(model_name, y_train, y_train_pred, y_test, y_test_pred):\n",
    "    print(f\"---{model_name}---\")\n",
    "    print(\"Train Metrics:\")\n",
    "    train_metrics = calculate_metrics(y_train, y_train_pred)\n",
    "    print(f\"R2: {train_metrics[0]}, RMSE: {train_metrics[1]}, MAE: {train_metrics[2]}, MSE: {train_metrics[3]}, RPD: {train_metrics[4]}\")\n",
    "    \n",
    "    print(\"Test Metrics:\")\n",
    "    test_metrics = calculate_metrics(y_test, y_test_pred)\n",
    "    print(f\"R2: {test_metrics[0]}, RMSE: {test_metrics[1]}, MAE: {test_metrics[2]}, MSE: {test_metrics[3]}, RPD: {test_metrics[4]}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Display metrics\n",
    "display_metrics(\"Elastic Net with RFE\", y_train, y_train_pred_elnet, y_test, y_test_pred_elnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd64999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "# Initialize the XGBoost regressor\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=175)\n",
    "\n",
    "# Initialize RFE with XGBoost as the estimator\n",
    "rfe = RFE(estimator=xgb, n_features_to_select=10, step=25)\n",
    "\n",
    "# Fit RFE\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_train.columns[rfe.support_]\n",
    "\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "\n",
    "# Train the model with selected features\n",
    "xgb.fit(X_train[selected_features], y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb.predict(X_test[selected_features])\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "# Predict and evaluate\n",
    "y_pred = stacking_regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"XGBRegressor MSE:\", mse)\n",
    "print(\"XGBRegressor R^2 Score:\", r2)\n",
    "print('XGBRegressor Absolute Error:',{mae})\n",
    "\n",
    "# Display feature importance\n",
    "importance = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Importance': xgb.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0c9796",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Generate a random regression problem\n",
    "X, y = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=100)\n",
    "\n",
    "# Train the XGBoost model\n",
    "model = XGBRegressor(objective='reg:squarederror', random_state=25)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Explain the model predictions using SHAP\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Plot feature importance\n",
    "shap.summary_plot(shap_values, X_test, feature_names=df.columns[:-1])\n",
    "\n",
    "# Get mean absolute SHAP values for feature importance\n",
    "shap_importance = np.abs(shap_values.values).mean(axis=0)\n",
    "shap_importance_df = pd.DataFrame({\n",
    "    'feature': df.columns[:-1],\n",
    "    'importance': shap_importance\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(shap_importance_df)\n",
    "\n",
    "# Select the top N features based on SHAP importance\n",
    "top_n_features = shap_importance_df['feature'].head(5).values\n",
    "print(f\"Top {len(top_n_features)} features: {top_n_features}\")\n",
    "\n",
    "# Transform the data to include only the selected features\n",
    "X_train_shap = X_train[:, shap_importance_df.index[:5]]\n",
    "X_test_shap = X_test[:, shap_importance_df.index[:5]]\n",
    "\n",
    "# Train the Elastic Net model with the selected features\n",
    "elnet_model = ElasticNet(random_state=42)\n",
    "elnet_model.fit(X_train_shap, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_elnet = elnet_model.predict(X_train_shap)\n",
    "y_test_pred_elnet = elnet_model.predict(X_test_shap)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rpd = np.std(y_true) / rmse\n",
    "    return r2, rmse, mae, mse, rpd\n",
    "\n",
    "def display_metrics(model_name, y_train, y_train_pred, y_test, y_test_pred):\n",
    "    print(f\"---{model_name}---\")\n",
    "    print(\"Train Metrics:\")\n",
    "    train_metrics = calculate_metrics(y_train, y_train_pred)\n",
    "    print(f\"R2: {train_metrics[0]}, RMSE: {train_metrics[1]}, MAE: {train_metrics[2]}, MSE: {train_metrics[3]}, RPD: {train_metrics[4]}\")\n",
    "    \n",
    "    print(\"Test Metrics:\")\n",
    "    test_metrics = calculate_metrics(y_test, y_test_pred)\n",
    "    print(f\"R2: {test_metrics[0]}, RMSE: {test_metrics[1]}, MAE: {test_metrics[2]}, MSE: {test_metrics[3]}, RPD: {test_metrics[4]}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Display metrics\n",
    "display_metrics(\"Elastic Net with SHAP-selected features\", y_train, y_train_pred_elnet, y_test, y_test_pred_elnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Generate a random regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=175)\n",
    "\n",
    "# Define a base model for RFE\n",
    "base_model = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "\n",
    "# Initialize RFE with the base model and select the top 5 features, using a moderate step size\n",
    "rfe = RFE(estimator=base_model, n_features_to_select=5, step=25)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_train.columns[rfe.support_]\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "\n",
    "# Transform the data to include only the selected features\n",
    "X_train_rfe = pd.DataFrame(rfe.transform(X_train), columns=selected_features)\n",
    "X_test_rfe = pd.DataFrame(rfe.transform(X_test), columns=selected_features)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_rfe = scaler.fit_transform(X_train_rfe)\n",
    "X_test_rfe = scaler.transform(X_test_rfe)\n",
    "\n",
    "# Train the CatBoost model with the selected features\n",
    "catboost_model = CatBoostRegressor(verbose=0, random_state=42)\n",
    "catboost_model.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_catboost = catboost_model.predict(X_train_rfe)\n",
    "y_test_pred_catboost = catboost_model.predict(X_test_rfe)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rpd = np.std(y_true) / rmse\n",
    "    return r2, rmse, mae, mse, rpd\n",
    "\n",
    "def display_metrics(model_name, y_train, y_train_pred, y_test, y_test_pred):\n",
    "    print(f\"---{model_name}---\")\n",
    "    print(\"Train Metrics:\")\n",
    "    train_metrics = calculate_metrics(y_train, y_train_pred)\n",
    "    print(f\"R2: {train_metrics[0]}, RMSE: {train_metrics[1]}, MAE: {train_metrics[2]}, MSE: {train_metrics[3]}, RPD: {train_metrics[4]}\")\n",
    "    \n",
    "    print(\"Test Metrics:\")\n",
    "    test_metrics = calculate_metrics(y_test, y_test_pred)\n",
    "    print(f\"R2: {test_metrics[0]}, RMSE: {test_metrics[1]}, MAE: {test_metrics[2]}, MSE: {test_metrics[3]}, RPD: {test_metrics[4]}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Display metrics\n",
    "display_metrics(\"CatBoost with RFE-selected features\", y_train, y_train_pred_catboost, y_test, y_test_pred_catboost)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
